{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "buvp8B8rLQlU",
        "D5RNy2znXsS_",
        "_eiCz9JWbsSa"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunal-vr0/Log-Anomaly-Detection/blob/main/Log_Anomaly_Final_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Anomaly Block"
      ],
      "metadata": {
        "id": "buvp8B8rLQlU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3e0n7M0LQOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y62OyEATLF79"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from torch.nn.utils import weight_norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrv81gK9pdc-",
        "outputId": "7042af23-64d2-4c55-d16d-fa5eae99518e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model).float()\n",
        "        pe.require_grad = False\n",
        "\n",
        "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
        "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
        "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DataEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model, dropout=0.0):\n",
        "        super(DataEmbedding, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
        "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.value_embedding(x) + self.position_embedding(x)\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "VYZ62le6MXIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TriangularCausalMask():\n",
        "    def __init__(self, B, L, device=\"cpu\"):\n",
        "        mask_shape = [B, 1, L, L]\n",
        "        with torch.no_grad():\n",
        "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
        "\n",
        "    @property\n",
        "    def mask(self):\n",
        "        return self._mask\n",
        "\n",
        "\n",
        "class AnomalyAttention(nn.Module):\n",
        "    def __init__(self, win_size, mask_flag=True, scale=None, attention_dropout=0.0, output_attention=False):\n",
        "        super(AnomalyAttention, self).__init__()\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "        window_size = win_size\n",
        "        self.distances = torch.zeros((window_size, window_size)).cuda()\n",
        "        for i in range(window_size):\n",
        "            for j in range(window_size):\n",
        "                self.distances[i][j] = abs(i - j)\n",
        "\n",
        "    def forward(self, queries, keys, values, sigma, attn_mask):\n",
        "        B, L, H, E = queries.shape\n",
        "        _, S, _, D = values.shape\n",
        "        scale = self.scale or 1. / sqrt(E)\n",
        "\n",
        "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
        "        if self.mask_flag:\n",
        "            if attn_mask is None:\n",
        "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
        "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
        "        attn = scale * scores\n",
        "\n",
        "        sigma = sigma.transpose(1, 2)  # B L H ->  B H L\n",
        "        window_size = attn.shape[-1]\n",
        "        sigma = torch.sigmoid(sigma * 5) + 1e-5\n",
        "        sigma = torch.pow(3, sigma) - 1\n",
        "        sigma = sigma.unsqueeze(-1).repeat(1, 1, 1, window_size)  # B H L L\n",
        "        prior = self.distances.unsqueeze(0).unsqueeze(0).repeat(sigma.shape[0], sigma.shape[1], 1, 1).cuda()\n",
        "        prior = 1.0 / (math.sqrt(2 * math.pi) * sigma) * torch.exp(-prior ** 2 / 2 / (sigma ** 2))\n",
        "\n",
        "        series = self.dropout(torch.softmax(attn, dim=-1))\n",
        "        V = torch.einsum(\"bhls,bshd->blhd\", series, values)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), series, prior, sigma)\n",
        "        else:\n",
        "            return (V.contiguous(), None)\n",
        "\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "\n",
        "        d_keys = d_keys or (d_model // n_heads)\n",
        "        d_values = d_values or (d_model // n_heads)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.inner_attention = attention\n",
        "        self.query_projection = nn.Linear(d_model,\n",
        "                                          d_keys * n_heads)\n",
        "        self.key_projection = nn.Linear(d_model,\n",
        "                                        d_keys * n_heads)\n",
        "        self.value_projection = nn.Linear(d_model,\n",
        "                                          d_values * n_heads)\n",
        "        self.sigma_projection = nn.Linear(d_model,\n",
        "                                          n_heads)\n",
        "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, _ = queries.shape\n",
        "        _, S, _ = keys.shape\n",
        "        H = self.n_heads\n",
        "        x = queries\n",
        "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
        "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
        "        values = self.value_projection(values).view(B, S, H, -1)\n",
        "        sigma = self.sigma_projection(x).view(B, L, H)\n",
        "\n",
        "        out, series, prior, sigma = self.inner_attention(\n",
        "            queries,\n",
        "            keys,\n",
        "            values,\n",
        "            sigma,\n",
        "            attn_mask\n",
        "        )\n",
        "        out = out.view(B, L, -1)\n",
        "\n",
        "        return self.out_projection(out), series, prior, sigma\n"
      ],
      "metadata": {
        "id": "sZCADaflMUzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.attention = attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        new_x, attn, mask, sigma = self.attention(\n",
        "            x, x, x,\n",
        "            attn_mask=attn_mask\n",
        "        )\n",
        "        x = x + self.dropout(new_x)\n",
        "        y = x = self.norm1(x)\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "\n",
        "        return self.norm2(x + y), attn, mask, sigma\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, attn_layers, norm_layer=None):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attn_layers = nn.ModuleList(attn_layers)\n",
        "        self.norm = norm_layer\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        # x [B, L, D]\n",
        "        series_list = []\n",
        "        prior_list = []\n",
        "        sigma_list = []\n",
        "        for attn_layer in self.attn_layers:\n",
        "            x, series, prior, sigma = attn_layer(x, attn_mask=attn_mask)\n",
        "            series_list.append(series)\n",
        "            prior_list.append(prior)\n",
        "            sigma_list.append(sigma)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        return x, series_list, prior_list, sigma_list\n",
        "\n",
        "\n",
        "class AnomalyTransformer(nn.Module):\n",
        "    def __init__(self, win_size, enc_in, c_out, d_model=512, n_heads=8, e_layers=3, d_ff=512,\n",
        "                 dropout=0.0, activation='gelu', output_attention=True):\n",
        "        super(AnomalyTransformer, self).__init__()\n",
        "        self.output_attention = output_attention\n",
        "\n",
        "        # Encoding\n",
        "        self.embedding = DataEmbedding(enc_in, d_model, dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        AnomalyAttention(win_size, False, attention_dropout=dropout, output_attention=output_attention),\n",
        "                        d_model, n_heads),\n",
        "                    d_model,\n",
        "                    d_ff,\n",
        "                    dropout=dropout,\n",
        "                    activation=activation\n",
        "                ) for l in range(e_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(d_model)\n",
        "        )\n",
        "\n",
        "        self.projection = nn.Linear(d_model, c_out, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc_out = self.embedding(x)\n",
        "        enc_out, series, prior, sigmas = self.encoder(enc_out)\n",
        "        enc_out = self.projection(enc_out)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return enc_out, series, prior, sigmas\n",
        "        else:\n",
        "            return enc_out  # [B, L, D]\n"
      ],
      "metadata": {
        "id": "HAslCSzWMRsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AnomalyTransformer(win_size=100, enc_in=50, c_out=50, e_layers=3)\n",
        "#optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()"
      ],
      "metadata": {
        "id": "DnKNGeBRLI5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/LLM_cx/Anomaly-Transformer/checkpoints/BGL__checkpoint_tf_50.pth'\n",
        "#model_path = '/content/drive/MyDrive/Anomaly-Transformer/checkpoints/BGL__checkpoint_tf_50.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1edMJIJJPA9q",
        "outputId": "212f122c-c801-4c8f-a10e-bdd230b77c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AnomalyTransformer(\n",
              "  (embedding): DataEmbedding(\n",
              "    (value_embedding): TokenEmbedding(\n",
              "      (tokenConv): Conv1d(50, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
              "    )\n",
              "    (position_embedding): PositionalEmbedding()\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "  )\n",
              "  (encoder): Encoder(\n",
              "    (attn_layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (attention): AttentionLayer(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (inner_attention): AnomalyAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (sigma_projection): Linear(in_features=512, out_features=8, bias=True)\n",
              "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (projection): Linear(in_features=512, out_features=50, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_kl_loss(p, q):\n",
        "    res = p * (torch.log(p + 0.0001) - torch.log(q + 0.0001))\n",
        "    return torch.mean(torch.sum(res, dim=-1), dim=1)"
      ],
      "metadata": {
        "id": "miSjA1rCYWa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def Tokenizer(text):\n",
        "  pattern = [r'\\d{4}-\\d{2}-\\d{2}-\\d{2}\\.\\d{2}\\.\\d{2}\\.\\d{6}', r'\\d{10}', r'\\d{4}.\\d{2}.\\d{2}', r':']\n",
        "  pattern = '|'.join(pattern)\n",
        "  text = re.sub(pattern, ' ', text)\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "z_jNXaENeQMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '1119725231 2005.06.25 R37-M1-N3-C:J15-U01 2005-06-25-11.47.11.451131 R37-M1-N3-C:J15-U01 RAS KERNEL INFO generating core.22224'\n",
        "#raw log entry\n",
        "import re\n",
        "def get_timestamp(text):\n",
        "  pattern = r'\\d{4}-\\d{2}-\\d{2}-\\d{2}\\.\\d{2}\\.\\d{2}\\.\\d+'\n",
        "  timestamp = {}\n",
        "  time = re.search(pattern, text)\n",
        "  if time:\n",
        "    x = time.group()\n",
        "  x = x.split('-')\n",
        "  timestamp['month'] = int(x[1])\n",
        "  timestamp['date'] = int(x[2])\n",
        "  y = x[3].split('.')\n",
        "  timestamp['hour'] = int(y[0])\n",
        "  timestamp['min'] = int(y[1])\n",
        "  return timestamp\n",
        "get_timestamp(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG1YjVouaQUq",
        "outputId": "092ffc15-b44f-45d3-a8a9-8520433995ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'month': 6, 'date': 25, 'hour': 11, 'min': 47}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ((month1*30 + date1)*24 + hour1)*60 + min1\n",
        "def diff(ref, temp):\n",
        "  minutes = (((temp['month']*30 + temp['date'])*24 + temp['hour'])*60 + temp['min']) - ref\n",
        "  if minutes < 0:\n",
        "    minutes = -1\n",
        "  return minutes"
      ],
      "metadata": {
        "id": "sK8h2LYBoWAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/LLM_cx/Anomaly-Transformer/dataset/My_BGL'\n",
        "def get_window(window, data_path):\n",
        "  for_Ref = 1\n",
        "  log_window = []\n",
        "  with open(data_path+'/validation.txt') as logs:\n",
        "    for log in logs:\n",
        "      if for_Ref:\n",
        "        ref = get_timestamp(str(log))\n",
        "        ref = ((ref['month']*30 + ref['date'])*24 + ref['hour'])*60 + ref['min']\n",
        "        for_Ref = 0\n",
        "      temp = get_timestamp(str(log))\n",
        "      period = diff(ref, temp)\n",
        "      if period < window:\n",
        "        log_window.append(log)\n",
        "      else:\n",
        "        break\n",
        "\n",
        "  return log_window"
      ],
      "metadata": {
        "id": "D4ptMqf_YL83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "class SegLoader(object):\n",
        "    def __init__(self, data_path, window_len, win_size, step):\n",
        "        self.step = step\n",
        "        self.win_size = win_size\n",
        "        self.scaler = StandardScaler()\n",
        "        self.win_len = window_len\n",
        "        test_data = pd.read_csv(data_path + '/test_tf_50.csv')\n",
        "        test_data = test_data[:self.win_len]\n",
        "        test_data = np.nan_to_num(test_data)\n",
        "        self.scaler.fit(test_data)\n",
        "        self.test = self.scaler.transform(test_data)\n",
        "        #print(\"test:\", self.test.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.test.shape[0] - self.win_size) // self.step + 1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index = index * self.step\n",
        "        return np.float32(self.test[index:index + self.win_size])"
      ],
      "metadata": {
        "id": "kruOrO3WfGW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predict"
      ],
      "metadata": {
        "id": "LYnwowzPXuin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "def predict(window):\n",
        "  #------defining parameters----------\n",
        "  temperature = 50\n",
        "  criterion = nn.MSELoss(reduce=False)\n",
        "  win_size = 100\n",
        "  anormly_ratio = 1\n",
        "  batch_size = 1024\n",
        "  win_size = 100\n",
        "  step = 100\n",
        "  #---------loading data--------------\n",
        "  data_path = '/content/drive/MyDrive/LLM_cx/Anomaly-Transformer/dataset/My_BGL'\n",
        "  log_window = get_window(window, data_path)  # gets raw log entries form the defined window size in a list\n",
        "  window_len = len(log_window)\n",
        "  dataset = SegLoader(data_path, window_len, win_size, step)\n",
        "  data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "  print('window_len: ', window_len)\n",
        "  #------------determining threshold-----------------\n",
        "  # (1) find the threshold\n",
        "  attens_energy = []\n",
        "  for i, input_data in enumerate(data_loader):\n",
        "    input = input_data.float().to(device)\n",
        "    output, series, prior, _ = model(input)\n",
        "    loss = torch.mean(criterion(input, output), dim=-1)\n",
        "\n",
        "    series_loss = 0.0\n",
        "    prior_loss = 0.0\n",
        "    for u in range(len(prior)):\n",
        "      if u == 0:\n",
        "        series_loss = my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,win_size)).detach()) * temperature\n",
        "        prior_loss = my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,win_size)),series[u].detach()) * temperature\n",
        "      else:\n",
        "        series_loss += my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,win_size)).detach()) * temperature\n",
        "        prior_loss += my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,win_size)),series[u].detach()) * temperature\n",
        "    # Metric\n",
        "    metric = torch.softmax((-series_loss - prior_loss), dim=-1)\n",
        "    cri = metric * loss\n",
        "    cri = cri.detach().cpu().numpy()\n",
        "    attens_energy.append(cri)\n",
        "  print('----------------')\n",
        "  attens_energy = np.concatenate(attens_energy, axis=0).reshape(-1)\n",
        "  test_energy = np.array(attens_energy)\n",
        "  combined_energy = test_energy\n",
        "  #combined_energy = np.concatenate([train_energy, test_energy], axis=0)\n",
        "  thresh = np.percentile(combined_energy, 100 - anormly_ratio)\n",
        "  #print(\"Threshold :\", thresh)\n",
        "\n",
        "  #-----------------creating predictions----------------\n",
        "  # (2) evaluation on the given dataset\n",
        "  attens_energy = []\n",
        "  for i, input_data in enumerate(data_loader):\n",
        "    input = input_data.float().to(device)\n",
        "    output, series, prior, _ = model(input)\n",
        "\n",
        "    loss = torch.mean(criterion(input, output), dim=-1)\n",
        "\n",
        "    series_loss = 0.0\n",
        "    prior_loss = 0.0\n",
        "    for u in range(len(prior)):\n",
        "      if u == 0:\n",
        "        series_loss = my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,win_size)).detach()) * temperature\n",
        "        prior_loss = my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,win_size)),series[u].detach()) * temperature\n",
        "      else:\n",
        "        series_loss += my_kl_loss(series[u], (prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,win_size)).detach()) * temperature\n",
        "        prior_loss += my_kl_loss((prior[u] / torch.unsqueeze(torch.sum(prior[u], dim=-1), dim=-1).repeat(1, 1, 1,win_size)),series[u].detach()) * temperature\n",
        "    metric = torch.softmax((-series_loss - prior_loss), dim=-1)\n",
        "    cri = metric * loss\n",
        "    cri = cri.detach().cpu().numpy()\n",
        "    attens_energy.append(cri)\n",
        "\n",
        "  attens_energy = np.concatenate(attens_energy, axis=0).reshape(-1)\n",
        "  test_energy = np.array(attens_energy)\n",
        "\n",
        "  pred = (test_energy > thresh).astype(int)\n",
        "  op_win = 5\n",
        "  peaks = np.where(pred == 1)\n",
        "  end = pred.shape[0]\n",
        "  for i in peaks[0]:\n",
        "    win_open = i-op_win\n",
        "    win_close = i+op_win\n",
        "    if win_open < 0:\n",
        "      win_open = 0\n",
        "    if win_close > end:\n",
        "      win_close = end-1\n",
        "    pred[win_open:win_close] = 1\n",
        "  loc = np.where(pred == 1)\n",
        "  print('anomalies: ', len(loc[0]))\n",
        "  anomaly = [log_window[i] for i in loc[0]]\n",
        "\n",
        "  return anomaly\n"
      ],
      "metadata": {
        "id": "T-0aPuZqqqvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anomaly = predict(2)\n",
        "anomaly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFA_q9R6ptt8",
        "outputId": "653097e4-5ef9-40d9-b4cf-ae778ff5bc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "window_len:  827\n",
            "----------------\n",
            "anomalies:  76\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1123637080 2005.08.09 R47-M1-N4-C:J06-U11 2005-08-09-18.24.40.416300 R47-M1-N4-C:J06-U11 RAS KERNEL INFO 6 ddr errors(s) detected and corrected on rank 0, symbol 5, bit 1\\n',\n",
              " '1123637080 2005.08.09 R52-M0-NB-C:J02-U01 2005-08-09-18.24.40.512804 R52-M0-NB-C:J02-U01 RAS KERNEL INFO 3 L3 directory error(s) (dcr 0x0152) detected and corrected\\n',\n",
              " '1123637080 2005.08.09 R56-M1-NA-C:J04-U01 2005-08-09-18.24.40.608671 R56-M1-NA-C:J04-U01 RAS KERNEL INFO 1 ddr errors(s) detected and corrected on rank 0, symbol 25, bit 1\\n',\n",
              " '1123637080 2005.08.09 R45-M0-N9-C:J08-U11 2005-08-09-18.24.40.703671 R45-M0-N9-C:J08-U11 RAS KERNEL INFO 1 ddr errors(s) detected and corrected on rank 0, symbol 35, bit 0\\n',\n",
              " '1123637080 2005.08.09 R72-M0-N0-C:J06-U01 2005-08-09-18.24.40.805377 R72-M0-N0-C:J06-U01 RAS KERNEL INFO 1 ddr errors(s) detected and corrected on rank 0, symbol 5, bit 0\\n',\n",
              " '1123637080 2005.08.09 R62-M1-NA-C:J08-U01 2005-08-09-18.24.40.901228 R62-M1-NA-C:J08-U01 RAS KERNEL INFO 1 ddr errors(s) detected and corrected on rank 0, symbol 22, bit 1\\n',\n",
              " '1123637094 2005.08.09 R74-M1-N0-C:J15-U11 2005-08-09-18.24.54.593139 R74-M1-N0-C:J15-U11 RAS KERNEL INFO CE sym 11, at 0x108a1240, mask 0x08\\n',\n",
              " '1123637094 2005.08.09 R74-M1-N0-C:J12-U01 2005-08-09-18.24.54.683042 R74-M1-N0-C:J12-U01 RAS KERNEL INFO CE sym 28, at 0x03189100, mask 0x10\\n',\n",
              " '1123637094 2005.08.09 R55-M0-N9-C:J06-U11 2005-08-09-18.24.54.772720 R55-M0-N9-C:J06-U11 RAS KERNEL INFO 1 tree receiver 2 in re-synch state event(s) (dcr 0x019a) detected\\n',\n",
              " '1123637094 2005.08.09 R22-M1-ND-C:J04-U11 2005-08-09-18.24.54.862699 R22-M1-ND-C:J04-U11 RAS KERNEL INFO CE sym 27, at 0x12747a80, mask 0x20\\n',\n",
              " '1123637094 2005.08.09 R37-M1-N9-C:J04-U11 2005-08-09-18.24.54.957978 R37-M1-N9-C:J04-U11 RAS KERNEL INFO CE sym 22, at 0x0374d540, mask 0x20\\n',\n",
              " '1123637095 2005.08.09 R24-M0-NE-C:J06-U11 2005-08-09-18.24.55.047673 R24-M0-NE-C:J06-U11 RAS KERNEL INFO CE sym 6, at 0x1971c160, mask 0x02\\n',\n",
              " '1123637095 2005.08.09 R51-M0-ND-C:J04-U01 2005-08-09-18.24.55.137208 R51-M0-ND-C:J04-U01 RAS KERNEL INFO CE sym 12, at 0x02cdd540, mask 0x02\\n',\n",
              " '1123637095 2005.08.09 R67-M0-N7-C:J08-U11 2005-08-09-18.24.55.227428 R67-M0-N7-C:J08-U11 RAS KERNEL INFO CE sym 29, at 0x13344660, mask 0x08\\n',\n",
              " '1123637095 2005.08.09 R67-M0-N2-C:J08-U01 2005-08-09-18.24.55.317118 R67-M0-N2-C:J08-U01 RAS KERNEL INFO CE sym 5, at 0x112ebea0, mask 0x10\\n',\n",
              " '1123637095 2005.08.09 R36-M1-N2-C:J08-U11 2005-08-09-18.24.55.412715 R36-M1-N2-C:J08-U11 RAS KERNEL INFO CE sym 35, at 0x09190d60, mask 0x10\\n',\n",
              " '1123637098 2005.08.09 R63-M0-N8-C:J17-U01 2005-08-09-18.24.58.936344 R63-M0-N8-C:J17-U01 RAS KERNEL INFO CE sym 35, at 0x1931cdc0, mask 0x80\\n',\n",
              " '1123637099 2005.08.09 R66-M1-N1-C:J15-U01 2005-08-09-18.24.59.026056 R66-M1-N1-C:J15-U01 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637099 2005.08.09 R66-M0-NF-C:J11-U11 2005-08-09-18.24.59.115060 R66-M0-NF-C:J11-U11 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637099 2005.08.09 R66-M0-NC-C:J17-U11 2005-08-09-18.24.59.204792 R66-M0-NC-C:J17-U11 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637099 2005.08.09 R43-M1-N8-C:J13-U11 2005-08-09-18.24.59.294631 R43-M1-N8-C:J13-U11 RAS KERNEL INFO CE sym 10, at 0x0b7c2060, mask 0x08\\n',\n",
              " '1123637099 2005.08.09 R64-M1-N6-C:J13-U01 2005-08-09-18.24.59.397959 R64-M1-N6-C:J13-U01 RAS KERNEL INFO CE sym 7, at 0x120ff4a0, mask 0x02\\n',\n",
              " '1123637099 2005.08.09 R42-M0-N7-C:J13-U11 2005-08-09-18.24.59.487766 R42-M0-N7-C:J13-U11 RAS KERNEL INFO CE sym 9, at 0x160d2a60, mask 0x08\\n',\n",
              " '1123637099 2005.08.09 R31-M1-NF-C:J15-U11 2005-08-09-18.24.59.576485 R31-M1-NF-C:J15-U11 RAS KERNEL INFO CE sym 34, at 0x19b019a0, mask 0x02\\n',\n",
              " '1123637099 2005.08.09 R34-M1-N8-C:J13-U11 2005-08-09-18.24.59.665988 R34-M1-N8-C:J13-U11 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637099 2005.08.09 R42-M1-N5-C:J15-U11 2005-08-09-18.24.59.755487 R42-M1-N5-C:J15-U11 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637107 2005.08.09 R72-M0-N2-C:J12-U11 2005-08-09-18.25.07.519443 R72-M0-N2-C:J12-U11 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637107 2005.08.09 R75-M0-N7-C:J14-U11 2005-08-09-18.25.07.614446 R75-M0-N7-C:J14-U11 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637107 2005.08.09 R75-M0-N7-C:J16-U01 2005-08-09-18.25.07.710590 R75-M0-N7-C:J16-U01 RAS KERNEL INFO CE sym 10, at 0x120055e0, mask 0x40\\n',\n",
              " '1123637107 2005.08.09 R12-M1-N2-C:J16-U01 2005-08-09-18.25.07.812362 R12-M1-N2-C:J16-U01 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637107 2005.08.09 R15-M0-N5-C:J10-U01 2005-08-09-18.25.07.914167 R15-M0-N5-C:J10-U01 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637108 2005.08.09 R01-M1-NF-C:J12-U11 2005-08-09-18.25.08.009459 R01-M1-NF-C:J12-U11 RAS KERNEL INFO CE sym 10, at 0x0585ca00, mask 0x80\\n',\n",
              " '1123637108 2005.08.09 R06-M1-N7-C:J16-U11 2005-08-09-18.25.08.062937 R06-M1-N7-C:J16-U11 RAS KERNEL INFO CE sym 15, at 0x07fbfee0, mask 0x40\\n',\n",
              " '1123637108 2005.08.09 R02-M1-N7-C:J16-U01 2005-08-09-18.25.08.128902 R02-M1-N7-C:J16-U01 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637108 2005.08.09 R05-M0-N1-C:J10-U01 2005-08-09-18.25.08.181162 R05-M0-N1-C:J10-U01 RAS KERNEL INFO CE sym 25, at 0x11297cc0, mask 0x80\\n',\n",
              " '1123637108 2005.08.09 R25-M0-NA-C:J14-U11 2005-08-09-18.25.08.279046 R25-M0-NA-C:J14-U11 RAS KERNEL INFO total of 1 ddr error(s) detected and corrected\\n',\n",
              " '1123637116 2005.08.09 R74-M0-N1-C:J05-U01 2005-08-09-18.25.16.943533 R74-M0-N1-C:J05-U01 RAS KERNEL INFO CE sym 30, at 0x042358a0, mask 0x20\\n',\n",
              " '1123637117 2005.08.09 R70-M1-NC-C:J09-U11 2005-08-09-18.25.17.050742 R70-M1-NC-C:J09-U11 RAS KERNEL INFO CE sym 26, at 0x146ad540, mask 0x10\\n',\n",
              " '1123637117 2005.08.09 R61-M1-N8-C:J03-U11 2005-08-09-18.25.17.146826 R61-M1-N8-C:J03-U11 RAS KERNEL INFO CE sym 35, at 0x0c3b8c40, mask 0x04\\n',\n",
              " '1123637117 2005.08.09 R71-M0-NC-C:J09-U11 2005-08-09-18.25.17.242661 R71-M0-NC-C:J09-U11 RAS KERNEL INFO total of 2 ddr error(s) detected and corrected\\n',\n",
              " '1123637117 2005.08.09 R03-M1-N9-C:J09-U11 2005-08-09-18.25.17.338325 R03-M1-N9-C:J09-U11 RAS KERNEL INFO CE sym 25, at 0x06c27c60, mask 0x40\\n',\n",
              " '1123637117 2005.08.09 R07-M0-N0-C:J09-U01 2005-08-09-18.25.17.434036 R07-M0-N0-C:J09-U01 RAS KERNEL INFO CE sym 4, at 0x18f28be0, mask 0x40\\n',\n",
              " '1123637117 2005.08.09 R53-M1-N9-C:J14-U01 2005-08-09-18.25.17.529318 R53-M1-N9-C:J14-U01 RAS KERNEL INFO CE sym 19, at 0x0701bc00, mask 0x01\\n',\n",
              " '1123637117 2005.08.09 R42-M0-ND-C:J16-U11 2005-08-09-18.25.17.633729 R42-M0-ND-C:J16-U11 RAS KERNEL INFO CE sym 4, at 0x1a5e2fe0, mask 0x04\\n',\n",
              " '1123637117 2005.08.09 R20-M1-NB-C:J16-U11 2005-08-09-18.25.17.721165 R20-M1-NB-C:J16-U11 RAS KERNEL INFO total of 2 ddr error(s) detected and corrected\\n',\n",
              " '1123637117 2005.08.09 R56-M1-NF-C:J14-U01 2005-08-09-18.25.17.816094 R56-M1-NF-C:J14-U01 RAS KERNEL INFO CE sym 19, at 0x0f707b40, mask 0x02\\n',\n",
              " '1123637125 2005.08.09 R77-M0-N6-C:J17-U01 2005-08-09-18.25.25.536638 R77-M0-N6-C:J17-U01 RAS KERNEL INFO CE sym 0, at 0x0abd5740, mask 0x08\\n',\n",
              " '1123637125 2005.08.09 R26-M0-N8-C:J13-U01 2005-08-09-18.25.25.620530 R26-M0-N8-C:J13-U01 RAS KERNEL INFO CE sym 19, at 0x0e867940, mask 0x40\\n',\n",
              " '1123637125 2005.08.09 R24-M0-N8-C:J17-U01 2005-08-09-18.25.25.708847 R24-M0-N8-C:J17-U01 RAS KERNEL INFO CE sym 26, at 0x19bd1c60, mask 0x80\\n',\n",
              " '1123637125 2005.08.09 R43-M1-N8-C:J13-U11 2005-08-09-18.25.25.797906 R43-M1-N8-C:J13-U11 RAS KERNEL INFO CE sym 10, at 0x0b7c2060, mask 0x01\\n',\n",
              " '1123637125 2005.08.09 R64-M1-N6-C:J13-U01 2005-08-09-18.25.25.899858 R64-M1-N6-C:J13-U01 RAS KERNEL INFO total of 4 ddr error(s) detected and corrected\\n',\n",
              " '1123637126 2005.08.09 R31-M1-NF-C:J15-U11 2005-08-09-18.25.26.001518 R31-M1-NF-C:J15-U11 RAS KERNEL INFO CE sym 34, at 0x19b019a0, mask 0x02\\n',\n",
              " '1123637126 2005.08.09 R67-M0-NE-C:J11-U11 2005-08-09-18.25.26.090888 R67-M0-NE-C:J11-U11 RAS KERNEL INFO CE sym 34, at 0x173e1420, mask 0x40\\n',\n",
              " '1123637126 2005.08.09 R65-M1-N9-C:J17-U01 2005-08-09-18.25.26.180596 R65-M1-N9-C:J17-U01 RAS KERNEL INFO CE sym 23, at 0x0e1ef660, mask 0x02\\n',\n",
              " '1123637126 2005.08.09 R73-M1-N0-C:J13-U11 2005-08-09-18.25.26.270529 R73-M1-N0-C:J13-U11 RAS KERNEL INFO CE sym 8, at 0x0d525760, mask 0x40\\n',\n",
              " '1123637126 2005.08.09 R57-M0-NE-C:J15-U01 2005-08-09-18.25.26.366099 R57-M0-NE-C:J15-U01 RAS KERNEL INFO CE sym 9, at 0x18d431c0, mask 0x10\\n',\n",
              " '1123637135 2005.08.09 R60-M1-N2-C:J10-U01 2005-08-09-18.25.35.734660 R60-M1-N2-C:J10-U01 RAS KERNEL INFO 56 torus sender x- retransmission error(s) (dcr 0x02f5) detected and corrected\\n',\n",
              " '1123637135 2005.08.09 R01-M1-NF-C:J12-U11 2005-08-09-18.25.35.836151 R01-M1-NF-C:J12-U11 RAS KERNEL INFO CE sym 10, at 0x0585ca00, mask 0x80\\n',\n",
              " '1123637135 2005.08.09 R06-M1-N7-C:J16-U11 2005-08-09-18.25.35.937289 R06-M1-N7-C:J16-U11 RAS KERNEL INFO total of 6 ddr error(s) detected and corrected\\n',\n",
              " '1123637136 2005.08.09 R22-M0-N4-C:J10-U01 2005-08-09-18.25.36.051108 R22-M0-N4-C:J10-U01 RAS KERNEL INFO CE sym 27, at 0x1236bae0, mask 0x02\\n',\n",
              " '1123637136 2005.08.09 R64-M0-N8-C:J12-U11 2005-08-09-18.25.36.152914 R64-M0-N8-C:J12-U11 RAS KERNEL INFO CE sym 21, at 0x15937660, mask 0x10\\n',\n",
              " '1123637136 2005.08.09 R23-M0-N0-C:J10-U01 2005-08-09-18.25.36.254328 R23-M0-N0-C:J10-U01 RAS KERNEL INFO CE sym 18, at 0x0e0272e0, mask 0x10\\n',\n",
              " '1123637136 2005.08.09 R47-M0-NF-C:J02-U11 2005-08-09-18.25.36.356020 R47-M0-NF-C:J02-U11 RAS KERNEL INFO CE sym 18, at 0x15afb0a0, mask 0x08\\n',\n",
              " '1123637136 2005.08.09 R47-M1-N4-C:J06-U11 2005-08-09-18.25.36.460400 R47-M1-N4-C:J06-U11 RAS KERNEL INFO total of 6 ddr error(s) detected and corrected\\n',\n",
              " '1123637136 2005.08.09 R61-M0-N1-C:J08-U11 2005-08-09-18.25.36.572553 R61-M0-N1-C:J08-U11 RAS KERNEL INFO CE sym 26, at 0x03231ca0, mask 0x10\\n',\n",
              " '1123637136 2005.08.09 R15-M1-NE-C:J06-U01 2005-08-09-18.25.36.673233 R15-M1-NE-C:J06-U01 RAS KERNEL INFO CE sym 21, at 0x17946860, mask 0x10\\n',\n",
              " '1123637146 2005.08.09 R15-M1-NE-C:J06-U01 2005-08-09-18.25.46.984219 R15-M1-NE-C:J06-U01 RAS KERNEL INFO CE sym 21, at 0x17946860, mask 0x10\\n',\n",
              " '1123637147 2005.08.09 R01-M0-N8-C:J02-U11 2005-08-09-18.25.47.068034 R01-M0-N8-C:J02-U11 RAS KERNEL INFO CE sym 2, at 0x0fa3d060, mask 0x08\\n',\n",
              " '1123637147 2005.08.09 R26-M0-N8-C:J13-U01 2005-08-09-18.25.47.348327 R26-M0-N8-C:J13-U01 RAS KERNEL INFO CE sym 19, at 0x0e867940, mask 0x40\\n',\n",
              " '1123637147 2005.08.09 R43-M1-N8-C:J13-U11 2005-08-09-18.25.47.427843 R43-M1-N8-C:J13-U11 RAS KERNEL INFO CE sym 10, at 0x0b7c2060, mask 0x08\\n',\n",
              " '1123637147 2005.08.09 R67-M0-NE-C:J11-U11 2005-08-09-18.25.47.523057 R67-M0-NE-C:J11-U11 RAS KERNEL INFO total of 13 ddr error(s) detected and corrected\\n',\n",
              " '1123637147 2005.08.09 R65-M1-N9-C:J17-U01 2005-08-09-18.25.47.630722 R65-M1-N9-C:J17-U01 RAS KERNEL INFO CE sym 23, at 0x0e1ef660, mask 0x02\\n',\n",
              " '1123637147 2005.08.09 R03-M1-N2-C:J13-U01 2005-08-09-18.25.47.684102 R03-M1-N2-C:J13-U01 RAS KERNEL INFO CE sym 26, at 0x164fd8c0, mask 0x02\\n',\n",
              " '1123637147 2005.08.09 R02-M1-NB-C:J15-U11 2005-08-09-18.25.47.737643 R02-M1-NB-C:J15-U11 RAS KERNEL INFO CE sym 5, at 0x146282e0, mask 0x04\\n',\n",
              " '1123637147 2005.08.09 R64-M1-N9-C:J03-U11 2005-08-09-18.25.47.791478 R64-M1-N9-C:J03-U11 RAS KERNEL INFO total of 13 ddr error(s) detected and corrected\\n',\n",
              " '1123637147 2005.08.09 R42-M1-ND-C:J07-U11 2005-08-09-18.25.47.947486 R42-M1-ND-C:J07-U11 RAS KERNEL INFO CE sym 20, at 0x0a508740, mask 0x02\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing API"
      ],
      "metadata": {
        "id": "_eiCz9JWbsSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fastapi uvicorn nest-asyncio pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJqRyYVo-d1Y",
        "outputId": "a2e29d0c-6ea3-4fd1-e749-60c2a89af316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "server setup"
      ],
      "metadata": {
        "id": "S04tng1pVkYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "#from model import AnomalyTransformer, predict_anomaly\n",
        "\n",
        "model = AnomalyTransformer(win_size=100, enc_in=50, c_out=50, e_layers=3)\n",
        "#model_path = '/content/drive/MyDrive/Anomaly-Transformer/checkpoints/BGL__checkpoint_tf_50.pth'\n",
        "model_path = '/content/drive/MyDrive/LLM_cx/Anomaly-Transformer/checkpoints/BGL__checkpoint_tf_50.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eifdz4EYaiA0",
        "outputId": "bbbcee46-91a0-44ad-b929-79277470edf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AnomalyTransformer(\n",
              "  (embedding): DataEmbedding(\n",
              "    (value_embedding): TokenEmbedding(\n",
              "      (tokenConv): Conv1d(50, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
              "    )\n",
              "    (position_embedding): PositionalEmbedding()\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "  )\n",
              "  (encoder): Encoder(\n",
              "    (attn_layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (attention): AttentionLayer(\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (inner_attention): AnomalyAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (sigma_projection): Linear(in_features=512, out_features=8, bias=True)\n",
              "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "        (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (projection): Linear(in_features=512, out_features=50, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eRWRNzHpChDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pypi-json\n",
        "import json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdNq7eaJ_OL1",
        "outputId": "6283a0cb-cc50-427e-dc26-40e91df7ee07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.0/127.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "class Item(BaseModel):\n",
        "  Time: int\n",
        "\n",
        "origins = [\"*\"]\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=origins,\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "@app.post('/predict')\n",
        "def predict_n(item : Item):\n",
        "  x = item.json()\n",
        "  x = json.loads(x)\n",
        "  x = x['Time']\n",
        "  y = predict(x)\n",
        "  return y"
      ],
      "metadata": {
        "id": "TzB-XS7x-YQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 'your authtoken'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9IySaArV5eG",
        "outputId": "83e3ffef-fe17-44b8-bf36-8d02bbf283f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 'your authtoken'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4E1sG6oWVTf",
        "outputId": "db23c60f-d35f-4a69-9e80-ffe71fddc159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "auth_token = \"your authtoken\"\n",
        "\n",
        "# Run the ngrok authentication command\n",
        "command = f\"ngrok authtoken {auth_token}\"\n",
        "process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "output, error = process.communicate()\n",
        "\n",
        "# Check if any error occurred during authentication\n",
        "if error:\n",
        "    print(\"Error occurred during authentication:\")\n",
        "    print(error.decode(\"utf-8\"))\n",
        "else:\n",
        "    print(\"Ngrok authentication successful!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OsLPPRBWvLS",
        "outputId": "cfa8d977-ce2b-450e-a89f-17efd9f6445e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok authentication successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Create tunnel\n",
        "public_url = ngrok.connect(8000, bind_tls=True, proto=\"http\")\n",
        "\n",
        "# Print the public URL\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R43g-S5SWxkf",
        "outputId": "7c742f75-42f1-4fd4-fcd1-3506becf761a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-07-14T06:12:16+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://72aa-34-141-248-192.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "# Allow for asyncio to work within the Jupyter notebook cell\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import uvicorn\n",
        "\n",
        "# Run the FastAPI app using uvicorn\n",
        "print(public_url)\n",
        "uvicorn.run(app)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzzzmHfJXARY",
        "outputId": "79ae0ec1-c1ce-4c90-8f4b-2813aed60d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NgrokTunnel: \"https://72aa-34-141-248-192.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [492]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  827\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  827\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  217\n",
            "----------------\n",
            "anomalies:  16\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  217\n",
            "----------------\n",
            "anomalies:  16\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     103.160.64.135:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     103.160.64.135:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     103.160.64.135:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     103.160.64.135:0 - \"GET / HTTP/1.1\" 404 Not Found\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  217\n",
            "----------------\n",
            "anomalies:  16\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     54.86.50.139:0 - \"POST /predict%20 HTTP/1.1\" 404 Not Found\n",
            "INFO:     54.86.50.139:0 - \"POST /predict%20?Time=10 HTTP/1.1\" 404 Not Found\n",
            "INFO:     54.86.50.139:0 - \"POST /predict%20?Time=1 HTTP/1.1\" 404 Not Found\n",
            "INFO:     54.86.50.139:0 - \"POST /predict%20?Time=1 HTTP/1.1\" 404 Not Found\n",
            "INFO:     54.86.50.139:0 - \"POST /predict%20?Time=1 HTTP/1.1\" 404 Not Found\n",
            "INFO:     54.86.50.139:0 - \"POST /predict?Time=1 HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     54.86.50.139:0 - \"POST /predict?Time=1 HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 422 Unprocessable Entity\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  217\n",
            "----------------\n",
            "anomalies:  16\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  5096\n",
            "----------------\n",
            "anomalies:  497\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  2327\n",
            "----------------\n",
            "anomalies:  227\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  2327\n",
            "----------------\n",
            "anomalies:  227\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 500 Internal Server Error\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 428, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/middleware/proxy_headers.py\", line 78, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/applications.py\", line 289, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/applications.py\", line 122, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 184, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 162, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/cors.py\", line 83, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/exceptions.py\", line 79, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/exceptions.py\", line 68, in __call__\n",
            "    await self.app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/middleware/asyncexitstack.py\", line 20, in __call__\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/middleware/asyncexitstack.py\", line 17, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 718, in __call__\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 276, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 66, in app\n",
            "    response = await func(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 273, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 192, in run_endpoint_function\n",
            "    return await run_in_threadpool(dependant.call, **values)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/concurrency.py\", line 41, in run_in_threadpool\n",
            "    return await anyio.to_thread.run_sync(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/lib/python3.10/asyncio/futures.py\", line 285, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/futures.py\", line 201, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-19-002cdbb4d7b3>\", line 21, in predict_n\n",
            "    y = predict(x)\n",
            "  File \"<ipython-input-14-45875d6fa016>\", line 16, in predict\n",
            "    dataset = SegLoader(data_path, window_len, win_size, step)\n",
            "  File \"<ipython-input-13-c2e7b06dbf14>\", line 12, in __init__\n",
            "    self.scaler.fit(test_data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\", line 824, in fit\n",
            "    return self.partial_fit(X, y, sample_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\", line 861, in partial_fit\n",
            "    X = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 565, in _validate_data\n",
            "    X = check_array(X, input_name=\"X\", **check_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 931, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 sample(s) (shape=(0, 50)) while a minimum of 1 is required by StandardScaler.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  964\n",
            "----------------\n",
            "anomalies:  86\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  217\n",
            "----------------\n",
            "anomalies:  16\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  217\n",
            "----------------\n",
            "anomalies:  16\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  217\n",
            "----------------\n",
            "anomalies:  16\n",
            "INFO:     54.86.50.139:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  915\n",
            "----------------\n",
            "anomalies:  86\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  964\n",
            "----------------\n",
            "anomalies:  86\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "window_len:  964\n",
            "----------------\n",
            "anomalies:  86\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "window_len:  915\n",
            "----------------\n",
            "anomalies:  86\n",
            "INFO:     34.83.197.104:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "window_len:  885\n",
            "----------------\n",
            "anomalies:  76\n",
            "INFO:     14.142.182.248:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [492]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill tunnel\n",
        "ngrok.disconnect(public_url=public_url)"
      ],
      "metadata": {
        "id": "lnp7-1DAXJIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCd0NFnvXQGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using API"
      ],
      "metadata": {
        "id": "0FU-RGSP3abj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pypi-json\n",
        "!pip install -q requests"
      ],
      "metadata": {
        "id": "dUg3TXlA3byo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests"
      ],
      "metadata": {
        "id": "Ug2zUEu83gyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://72aa-34-141-248-192.ngrok-free.app/'  #plug in the ulr you get form ngrok\n",
        "url = url+'predict'\n",
        "data = {'Time': 110}\n",
        "data = json.dumps(data)\n",
        "response = requests.post(url, data = data)\n",
        "x = response.json()\n",
        "for log in x:\n",
        "  print(log)"
      ],
      "metadata": {
        "id": "t8EZR3Qq3m0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}